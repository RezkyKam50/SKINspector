source ./scripts/gcc_switcher.sh
source ./scripts/cuda_toolkit.sh

CMAKE_ARGS="-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=89-real -DGGML_CUDA_KV_CACHE_QUANTS=ON -DGGML_CUDA_FORCE_MMQ=ON -DGGML_OPENMP=ON -DGGML_FORCE_CUBLAS=OFF -DGGML_BLAS=OFF -DGGML_CUDA_FA=ON -DGGML_CUDA_FA_ALL_QUANTS=ON -DGGML_CUDA_F16=ON -DGGML_CUDA_ENABLE_UNIFIED_MEMORY=ON -DGGML_CUDA_FORCE_DMMV=ON -DGGML_CUDA_DMMV_X=512 -DGGML_CUDA_COMPRESSION_MODE=speed -DGGML_LTO=ON -DGGML_CUDA_DMMV_F16=ON -DGGML_CUDA_FORCE_F32_DMMV=OFF -DGGML_CUDA_MMV_F16=ON -DGGML_CUDA_KQUANTS=ON -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_FLAGS=$ENHANCED_C_FLAGS -DCMAKE_CXX_FLAGS=$ENHANCED_CXX_FLAGS -DCMAKE_CUDA_FLAGS=$CUDA_FLAGS -DGGML_NATIVE=ON -DGGML_CUDA_USE_TENSORCORES=ON -DBUILD_SHARED_LIBS=OFF -DGGML_CUDA_MAX_DEVICES=1 -DGGML_CUDA_GRAPHS=ON -DGGML_CUDA_GRAPHS_MAX_STREAMS=1024 -DGGML_ACCELERATE=OFF -DGGML_OPENBLAS=OFF -DGGML_OPENCL=OFF -DGGML_LLAMAFILE=OFF -DGGML_CUDA_NO_PEER_COPY=ON -DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON -DGGML_CUDA_FORCE_KERNEL_OPTIMIZATION=ON -DGGML_CUDA_UVM_PREFETCH=ON -DGGML_AVX512=ON -DGGML_AVX512_VBMI=ON -DGGML_AVX512_VNNI=ON -DGGML_AVX512_BF16=ON -DGGML_CPU_REPACK=ON -DGGML_CCACHE=ON -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CUDA_COMPILER_LAUNCHER=ccache -DLLAMA_CURL=OFF" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir
