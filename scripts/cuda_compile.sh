rm -rf ./3rdparty/llama.cpp/build && mkdir ./3rdparty/llama.cpp/build && cd ./3rdparty/llama.cpp/build 

ENHANCED_C_FLAGS="-O3 -march=native -mtune=native"
ENHANCED_CXX_FLAGS="$ENHANCED_C_FLAGS"
CUDA_HOST_FLAGS="-O3 -march=native -mtune=native"

CUDA_FLAGS="\
-O3 \
--use_fast_math"

cmake .. -G Ninja \
-DGGML_CUDA=ON \
-DCMAKE_CUDA_ARCHITECTURES="89-real" \
-DGGML_CUDA_KV_CACHE_QUANTS=ON \
-DGGML_CUDA_FORCE_MMQ=ON \
-DGGML_OPENMP=ON \
-DGGML_FORCE_CUBLAS=OFF \
-DGGML_BLAS=OFF \
-DGGML_CUDA_FA=ON \
-DGGML_CUDA_FA_ALL_QUANTS=ON \
-DGGML_CUDA_F16=ON \
-DGGML_CUDA_ENABLE_UNIFIED_MEMORY=ON \
-DGGML_CUDA_FORCE_DMMV=ON \
-DGGML_CUDA_DMMV_X=512 \
-DGGML_CUDA_COMPRESSION_MODE=speed \
-DGGML_LTO=ON \
-DGGML_CUDA_DMMV_F16=ON \
-DGGML_CUDA_FORCE_F32_DMMV=OFF \
-DGGML_CUDA_MMV_F16=ON \
-DGGML_CUDA_KQUANTS=ON \
-DCMAKE_BUILD_TYPE=Release \
-DCMAKE_C_FLAGS="$ENHANCED_C_FLAGS" \
-DCMAKE_CXX_FLAGS="$ENHANCED_CXX_FLAGS" \
-DCMAKE_CUDA_FLAGS="$CUDA_FLAGS" \
-DGGML_NATIVE=ON \
-DGGML_CUDA_USE_TENSORCORES=ON \
-DBUILD_SHARED_LIBS=OFF \
-DGGML_CUDA_MAX_DEVICES=1 \
-DGGML_CUDA_GRAPHS=ON \
-DGGML_CUDA_GRAPHS_MAX_STREAMS=1024 \
-DGGML_ACCELERATE=OFF \
-DGGML_OPENBLAS=OFF \
-DGGML_OPENCL=OFF \
-DGGML_LLAMAFILE=OFF \
-DGGML_CUDA_NO_PEER_COPY=ON \
-DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON \
-DGGML_CUDA_FORCE_KERNEL_OPTIMIZATION=ON \
-DGGML_CUDA_UVM_PREFETCH=ON \
-DGGML_AVX512=ON \
-DGGML_AVX512_VBMI=ON \
-DGGML_AVX512_VNNI=ON \
-DGGML_AVX512_BF16=ON \
-DGGML_CPU_REPACK=ON \
-DGGML_CCACHE=ON \
-DCMAKE_C_COMPILER_LAUNCHER=ccache \
-DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
-DCMAKE_CUDA_COMPILER_LAUNCHER=ccache \
-DLLAMA_CURL=OFF

ninja

