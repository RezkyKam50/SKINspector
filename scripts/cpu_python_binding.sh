#!/bin/bash

source ./scripts/gcc_switcher.sh

CMAKE_ARGS="-DGGML_CUDA=OFF -DGGML_CUDA_FORCE_MMQ=ON -DGGML_OPENMP=ON -DGGML_AVX512=ON -DGGML_AVX512_VBMI=ON -DGGML_AVX512_VNNI=ON -DGGML_AVX512_BF16=ON -DGGML_CPU_REPACK=ON -DGGML_CCACHE=ON -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DLLAMA_CURL=OFF" \
    FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir